{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10489956,"sourceType":"datasetVersion","datasetId":6494946}],"dockerImageVersionId":30840,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-17T18:25:38.488109Z","iopub.execute_input":"2025-01-17T18:25:38.488396Z","iopub.status.idle":"2025-01-17T18:25:39.392680Z","shell.execute_reply.started":"2025-01-17T18:25:38.488367Z","shell.execute_reply":"2025-01-17T18:25:39.391848Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/toxic-data/kaggle_data/train_y.csv\n/kaggle/input/toxic-data/kaggle_data/train_x.csv\n/kaggle/input/toxic-data/kaggle_data/test_x.csv\n/kaggle/input/toxic-data/kaggle_data/val_x.csv\n/kaggle/input/toxic-data/kaggle_data/val_y.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"data_dir = '/kaggle/input/toxic-data/kaggle_data/'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T18:25:41.289730Z","iopub.execute_input":"2025-01-17T18:25:41.290011Z","iopub.status.idle":"2025-01-17T18:25:41.293894Z","shell.execute_reply.started":"2025-01-17T18:25:41.289989Z","shell.execute_reply":"2025-01-17T18:25:41.293033Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import pandas as pd\ndf_x = pd.read_csv(data_dir + 'train_x.csv')\ndf_x_= pd.read_csv(data_dir + 'val_x.csv')\ndf_x = pd.concat([df_x, df_x_], axis=0, ignore_index=True)\ndf_y = pd.read_csv(data_dir + 'train_y.csv')\ndf_y_= pd.read_csv(data_dir + 'val_y.csv')\ndf_y = pd.concat([df_y, df_y_], axis=0, ignore_index=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T18:25:44.478719Z","iopub.execute_input":"2025-01-17T18:25:44.478996Z","iopub.status.idle":"2025-01-17T18:25:47.592478Z","shell.execute_reply.started":"2025-01-17T18:25:44.478973Z","shell.execute_reply":"2025-01-17T18:25:47.591787Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"df_x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T18:25:47.593564Z","iopub.execute_input":"2025-01-17T18:25:47.593784Z","iopub.status.idle":"2025-01-17T18:25:47.616764Z","shell.execute_reply.started":"2025-01-17T18:25:47.593765Z","shell.execute_reply":"2025-01-17T18:25:47.615974Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"        index                                             string\n0           0                         even up here.......BLACKS!\n1           1  Blame men.  There's always an excuse to blame ...\n2           2  You have no business making any comments on th...\n3           3  \"Let's get the black folks and the white folks...\n4           4  I guess the issue is people not willing to put...\n...       ...                                                ...\n314213  45175  Yes, lynching means hanging - violent death.  ...\n314214  45176  Oh my G-d, a group of men in their 60's and 70...\n314215  45177  \"Donald Trump’s refugee crisis?\"\\n\\nDon't blam...\n314216  45178  Under JPII we moved away from all that love st...\n314217  45179  In your rush to bash feminists, as usual you m...\n\n[314218 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>string</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>even up here.......BLACKS!</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Blame men.  There's always an excuse to blame ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>You have no business making any comments on th...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>\"Let's get the black folks and the white folks...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>I guess the issue is people not willing to put...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>314213</th>\n      <td>45175</td>\n      <td>Yes, lynching means hanging - violent death.  ...</td>\n    </tr>\n    <tr>\n      <th>314214</th>\n      <td>45176</td>\n      <td>Oh my G-d, a group of men in their 60's and 70...</td>\n    </tr>\n    <tr>\n      <th>314215</th>\n      <td>45177</td>\n      <td>\"Donald Trump’s refugee crisis?\"\\n\\nDon't blam...</td>\n    </tr>\n    <tr>\n      <th>314216</th>\n      <td>45178</td>\n      <td>Under JPII we moved away from all that love st...</td>\n    </tr>\n    <tr>\n      <th>314217</th>\n      <td>45179</td>\n      <td>In your rush to bash feminists, as usual you m...</td>\n    </tr>\n  </tbody>\n</table>\n<p>314218 rows × 2 columns</p>\n</div>"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# count for text len distrubution for better max_len choice\ndf_x['string'] = df_x['string'].astype(str).fillna('')\nlength = df_x['string'].apply(lambda x: len(x.split()))\n\n\nplt.hist(length, bins=50)\nplt.xlabel('length')\nplt.ylabel('')\nplt.title('max_len')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T18:25:49.866945Z","iopub.execute_input":"2025-01-17T18:25:49.867222Z","iopub.status.idle":"2025-01-17T18:25:51.264165Z","shell.execute_reply.started":"2025-01-17T18:25:49.867199Z","shell.execute_reply":"2025-01-17T18:25:51.263178Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"\n# !pip install transformers datasets evaluate\n\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom datasets import Dataset, ClassLabel\nfrom transformers import (\n    AutoTokenizer,\n    AutoConfig,\n    BertPreTrainedModel,\n    BertForSequenceClassification,\n    Trainer,\n    TrainingArguments,\n    get_linear_schedule_with_warmup\n)\nimport torch\nimport torch.nn as nn\nimport numpy as np\nimport logging\nfrom evaluate import load\nfrom torch.utils.data import DataLoader \nfrom tqdm import tqdm\nfrom torch.optim.lr_scheduler import CosineAnnealingWarmRestarts \n# FGM：adversarial training involves attacking the input embeddings\nclass FGM():\n    \n    def __init__(self, model):\n        self.model = model\n        self.backup = {}\n\n    def attack(self, epsilon=1., emb_name='bert.embeddings.word_embeddings'):\n        '''\n        emb_name:specific embedding layer name\n        '''\n        for name, param in self.model.named_parameters():\n            if param.requires_grad and emb_name in name:\n                self.backup[name] = param.data.clone()\n                norm = torch.norm(param.grad)\n                if norm != 0 and not torch.isnan(norm):\n                    r_at = epsilon * param.grad / norm\n                    param.data.add_(r_at)\n\n    def restore(self, emb_name='bert.embeddings.word_embeddings'):\n        for name, param in self.model.named_parameters():\n            if param.requires_grad and emb_name in name:\n                assert name in self.backup\n                param.data = self.backup[name]\n        self.backup = {}\n\n\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n# #  for Colab running\n# from google.colab import drive\n# drive.mount('/content/drive')\n\n# # for Kaggle running\n# data_dir = '/content/drive/MyDrive/Colab_Notebooks/deep/toxic/scr/kaggle_data/'\n  \n\n\ndf = pd.merge(df_x, df_y, left_index=True, right_index=True)\n\n\ndf = df.dropna(subset=['string'])\nprint(f\"total row: {len(df)}\")\n\n# first run with train & val\n# train_df, val_df = train_test_split(df, test_size=0.1, random_state=42)\n\ntrain_df = df.copy() \n# could check label distrubution\nprint(\"train label distrubution:\")\n\nprint(train_df['y'].value_counts())\n# print(\"val label distrubution:\")\n# print(val_df['y'].value_counts())\n\n\n\nmodel_name = \"bert-base-uncased\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\n\n\n# train_dataset = Dataset.from_pandas(train_df)\n# val_dataset = Dataset.from_pandas(val_df)\ntrain_dataset = Dataset.from_pandas(train_df)\n\ndef tokenize_function(example):\n    return tokenizer(\n        example[\"string\"],\n        truncation=True,\n        padding=\"max_length\",\n        max_length=150\n    )\n\n\n\ntrain_dataset = train_dataset.map(tokenize_function, batched=True, remove_columns=['string', 'index'])\n# val_dataset = val_dataset.map(tokenize_function, batched=True, remove_columns=['string', 'index'])\n\ntrain_dataset = train_dataset.rename_column(\"y\", \"labels\")\n# val_dataset = val_dataset.rename_column(\"y\", \"labels\")\n\nprint(f\"train set label missing: {train_dataset.filter(lambda x: x['labels'] is None).num_rows}\")\n# print(f\"val set label missing: {val_dataset.filter(lambda x: x['labels'] is None).num_rows}\")\n\n\ntrain_dataset = train_dataset.filter(lambda x: len(x['input_ids']) > 0 and len(x['attention_mask']) > 0)\n# val_dataset = val_dataset.filter(lambda x: len(x['input_ids']) > 0 and len(x['attention_mask']) > 0)\n\nnum_labels = 2\n\n\ntrain_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n# val_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"] )\n\n\nprint(train_dataset[0])\n\n\nconfig = AutoConfig.from_pretrained(\n    model_name,\n    num_labels=num_labels,\n    finetuning_task=\"sequence_classification\"\n)\n\n# Check and use multiple GPUs if available\nnum_gpus = torch.cuda.device_count()\nprint(f\"Number of GPUs available: {num_gpus}\")\n\n# for double T4 GPU\nif num_gpus > 1:\n    print(f\"Using {num_gpus} GPUs for training.\")\n    model = nn.DataParallel(model)\n\n\nmodel = BertForSequenceClassification.from_pretrained(\n    model_name,\n    config=config\n)\n\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\n\nfrom torch.optim import AdamW\n\noptimizer = AdamW(model.parameters(), lr=2e-5)\n\n\nepochs = 3\nbatch_size = 32\nepsilon = 1.0  # Adversarial Disturbance\n\n\ntrain_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\n# val_loader = DataLoader(val_dataset, batch_size=batch_size)\n\n#  FGM\nfgm = FGM(model)\n\n\ncriterion = nn.CrossEntropyLoss()\n\nnum_training_steps = len(train_loader) * epochs\n# num_warmup_steps = int(0.1 * num_training_steps)\n\n# # first test schedule\n# scheduler = get_linear_schedule_with_warmup(\n#     optimizer,\n#     num_warmup_steps=num_warmup_steps,\n#     num_training_steps=num_training_steps\n# )\n\n# second test schedule\nscheduler = CosineAnnealingWarmRestarts(\n    optimizer,\n    T_0=10,          \n    T_mult=2,        \n    eta_min=1e-6,    # mini learning rate \n)\n\n# train\nfor epoch in range(epochs):\n    model.train()\n    total_loss = 0\n    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\")\n\n    for batch in progress_bar:\n        \n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['labels'].to(device)\n\n        \n        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n        loss = outputs.loss\n        total_loss += loss.item()\n\n        \n        loss.backward()\n\n        # AD\n        fgm.attack(epsilon=epsilon)  \n\n        # Forward propagation with perturbed input\n        outputs_adv = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n        loss_adv = outputs_adv.loss\n            \n        # Back propagation with perturbed grad\n        loss_adv.backward()\n\n        # restore\n        fgm.restore()\n\n        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n\n\n        optimizer.step()\n        scheduler.step()\n        optimizer.zero_grad()\n\n        progress_bar.set_postfix({'loss': loss.item(), 'loss_adv': loss_adv.item()})\n\n    avg_loss = total_loss / len(train_loader)\n    print(f\"Epoch {epoch+1} Training Loss: {avg_loss}\")\n\n    # 验证\n    # model.eval()\n    # correct = 0\n    # total = 0\n    # val_loss = 0\n    # with torch.no_grad():\n    #     for batch in tqdm(val_loader, desc=\"Validation\"):\n    #         input_ids = batch['input_ids'].to(device)\n    #         attention_mask = batch['attention_mask'].to(device)\n    #         labels = batch['labels'].to(device)\n\n    #         outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n    #         loss = outputs.loss\n    #         val_loss += loss.item()\n\n    #         logits = outputs.logits\n    #         predictions = torch.argmax(logits, dim=-1)\n    #         correct += (predictions == labels).sum().item()\n    #         total += labels.size(0)\n\n    # avg_val_loss = val_loss / len(val_loader)\n    # accuracy = correct / total\n    # print(f\"Epoch {epoch+1} Validation Loss: {avg_val_loss}, Accuracy: {accuracy}\")\n    model_save_path = '/kaggle/working/' + 'trained_model_2_{}'.format(epoch)\n    model.save_pretrained(model_save_path)\n    tokenizer.save_pretrained(model_save_path)\n    print(f\"model save to {model_save_path}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T18:41:24.083804Z","iopub.execute_input":"2025-01-17T18:41:24.084113Z"}},"outputs":[{"name":"stdout","text":"total row: 314218\ntrain label distrubution:\ny\n0    278648\n1     35570\nName: count, dtype: int64\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/314218 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9dda9541f73a4d428bd87f5eaf6a97ba"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/314218 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aa44beb2085240e287b238638cd67d82"}},"metadata":{}},{"name":"stdout","text":"train set label missing: 0\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/314218 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4677cfb064e84c66a6d13482319f8f92"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"{'labels': tensor(1), 'input_ids': tensor([  101,  2130,  2039,  2182,  1012,  1012,  1012,  1012,  1012,  1012,\n         1012, 10823,   999,   102,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0])}\nNumber of GPUs available: 1\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/3: 100%|██████████| 9820/9820 [2:31:06<00:00,  1.08it/s, loss=0.191, loss_adv=0.266]    \n","output_type":"stream"},{"name":"stdout","text":"Epoch 1 Training Loss: 0.20355768755700462\nmodel save to /kaggle/working/trained_model_2_0\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/3:  56%|█████▌    | 5497/9820 [1:24:35<1:06:16,  1.09it/s, loss=0.0375, loss_adv=0.0397]","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"df_test = pd.read_csv(data_dir + 'test_x.csv')  \n\n\ntest_inputs = df_test.loc[:, 'string'].fillna('').tolist()\n\n\ninputs = tokenizer(\n    test_inputs,\n    return_tensors=\"pt\",\n    truncation=True,\n    max_length=128,\n    padding=True\n).to(device)\n\n\npredict_batch_size = 32\npredictions = []\nmodel.eval()\n\nfor i in range(0, len(test_inputs), predict_batch_size):\n    batch_inputs = {key: value[i:i+predict_batch_size].to(device) for key, value in inputs.items()}\n    with torch.no_grad():\n        outputs = model(**batch_inputs)\n        logits = outputs.logits\n        batch_preds = torch.argmax(logits, dim=-1).cpu().tolist()\n        predictions.extend(batch_preds)\n\nprint('finish testing', len(predictions), 'sample to test')\n\npred_df = pd.DataFrame({\n    'ID': range(len(predictions)),\n    'pred': predictions\n})\n\noutput_csv_path = '/kaggle/working/' + 'prediction_2.csv' \npred_df.to_csv(output_csv_path, index=False)\nprint(f'save to {output_csv_path}')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nmodel_save_path = '/kaggle/working/' + 'trained_model_2'\nmodel.save_pretrained(model_save_path)\ntokenizer.save_pretrained(model_save_path)\nprint(f\"model save to {model_save_path}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-17T17:34:02.590654Z","iopub.execute_input":"2025-01-17T17:34:02.591041Z","iopub.status.idle":"2025-01-17T17:34:03.729821Z","shell.execute_reply.started":"2025-01-17T17:34:02.591010Z","shell.execute_reply":"2025-01-17T17:34:03.728737Z"}},"outputs":[{"name":"stdout","text":"model save to /kaggle/working/trained_model\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}